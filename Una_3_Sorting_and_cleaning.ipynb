{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Una -  3. Sorting_and_cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UnaRam/pythonFundamemtals/blob/main/Una_3_Sorting_and_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CVoh0pMzW0l"
      },
      "source": [
        "# Sorting and cleaning \n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In order to effectively analyse a dataset, often we need to prepare it first. \n",
        "Before a dataset is ready to be analysed we might need to:  \n",
        "\n",
        "* sort the data (can be a series or dataframe)  \n",
        "* remove any NaN values or drop NA values   \n",
        "* remove duplicate records (identical rows)  \n",
        "* normalise data in dataframe columns so that has a common scale [reference](https://towardsai.net/p/data-science/how-when-and-why-should-you-normalize-standardize-rescale-your-data-3f083def38ff#:~:text=Similarly%2C%20the%20goal%20of%20normalization,dataset%20does%20not%20require%20normalization.&text=So%20we%20normalize%20the%20data,variables%20to%20the%20same%20range.)\n",
        "\n",
        "## Sorting the data  \n",
        "---\n",
        "\n",
        "\n",
        "Typically we want to sort data by the values in one or more columns in the dataframe  \n",
        "\n",
        "To sort the dataframe by series we use the pandas function **sort_values()**.  \n",
        "\n",
        "By default `sort_values()` sorts into ascending order.\n",
        "\n",
        "* sort by a single column e.g.\n",
        "  * `df.sort_values(\"Make\") `\n",
        "* sort by multiple columns e.g. \n",
        "  * `df.sort_values(by = [\"Model\", \"Make\"]) `\n",
        "    * this sorts by Model, then my Make \n",
        "* sort in *descending* order\n",
        "  * `df.sort_values(by = \"Make\", ascending = False)`\n",
        "  * `df.sort_values(by = [\"Make\", \"Model\"], ascending = False])`  \n",
        "\n",
        "Dataframes are mostly **immutable**, ie changes like sort_values do not change the dataframe permanently, they just change it for the time that the instruction is being used.\n",
        "\n",
        "`df.sort_values(by='Make')` *dataframe is now in sorted order and can be copied to a new dataframe*  \n",
        "`df_sorted_on_make` *original dataframe, df, will be as it was - unsorted* \n",
        "\n",
        "To **split** columns away from the dataframe after sorting, do this in the same instruction, e.g.:\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]]`\n",
        "\n",
        "This sorts on Make and then Model in descending order, then splits off the Make and Model columns.\n",
        "\n",
        "`df.sort_values(by = [\"Make\", \"Model\"], ascending = False])[[\"Make\", \"Model\"]].head()`\n",
        "\n",
        "This sorts on Make and then Model, then splits off the Make and Model columns and then splits off the first 5 rows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANKknIx8E-hN"
      },
      "source": [
        "### Exercise 1 - get data, sort by happiness score \n",
        "---\n",
        "\n",
        "Read data into variable called **happiness** from the Excel file on Happiness Data at this link: https://github.com/futureCodersSE/working-with-data/blob/main/Happiness-Data/2015.xlsx?raw=true\n",
        "\n",
        "Write a function called **sorted_rank** to display first 5 rows of data  \n",
        "\n",
        "The data is currently sorted by Happiness Rank...\n",
        "*  sort the data by Happiness Score in ascending order\n",
        "*  display sorted table\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jkvFGvJtHXiH",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 566
        },
        "outputId": "1a440334-439e-407b-ad1f-2254c0184698"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "def sorted_rank(df):\n",
        "# add code below to return a series sorted by Happiness Score in ascending order\n",
        "  # print(\"inside fn\")\n",
        "  # print(df.head(5))\n",
        "  df_sorted_on_happiness_score = df.sort_values(\"Happiness Score\")\n",
        "  print(df_sorted_on_happiness_score.head(10))\n",
        "  print(df_sorted_on_happiness_score.tail(10))\n",
        "\n",
        "\n",
        "  return df_sorted_on_happiness_score\n",
        "\n",
        "#read file into variable happiness\n",
        "uploaded = files.upload()\n",
        "happiness = pd.read_excel(uploaded['2015.xlsx'])\n",
        "# happiness.head(10)\n",
        "# sorted_rank(happiness)\n",
        "\n",
        "#Write a function called sorted_rank to display first 5 rows of data\n",
        "# The code below will run and test your code to see if the first row of your series is correct \n",
        "actual = sorted_rank(happiness).index[0]\n",
        "expected = 157\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Well done, test passed\")\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3521c08b-4c40-4a13-b9b1-09a91311e3e3\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3521c08b-4c40-4a13-b9b1-09a91311e3e3\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 2015.xlsx to 2015 (13).xlsx\n",
            "          Country  ... Dystopia Residual\n",
            "157          Togo  ...           1.56726\n",
            "156       Burundi  ...           1.83302\n",
            "155         Syria  ...           0.32858\n",
            "154         Benin  ...           1.63328\n",
            "153        Rwanda  ...           0.67042\n",
            "152   Afghanistan  ...           1.95210\n",
            "151  Burkina Faso  ...           1.46494\n",
            "150   Ivory Coast  ...           1.41723\n",
            "149        Guinea  ...           1.99172\n",
            "148          Chad  ...           1.94296\n",
            "\n",
            "[10 rows x 12 columns]\n",
            "       Country                     Region  ...  Generosity  Dystopia Residual\n",
            "9    Australia  Australia and New Zealand  ...     0.43562            2.26646\n",
            "8  New Zealand  Australia and New Zealand  ...     0.47501            2.26425\n",
            "7       Sweden             Western Europe  ...     0.36262            2.37119\n",
            "6  Netherlands             Western Europe  ...     0.47610            2.46570\n",
            "5      Finland             Western Europe  ...     0.23351            2.61955\n",
            "4       Canada              North America  ...     0.45811            2.45176\n",
            "3       Norway             Western Europe  ...     0.34699            2.46531\n",
            "2      Denmark             Western Europe  ...     0.34139            2.49204\n",
            "1      Iceland             Western Europe  ...     0.43630            2.70201\n",
            "0  Switzerland             Western Europe  ...     0.29678            2.51738\n",
            "\n",
            "[10 rows x 12 columns]\n",
            "Well done, test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_iomqRTH8LA"
      },
      "source": [
        "### Exercise 2 - sort by multiple columns, display the first 5 rows \n",
        "---\n",
        "\n",
        "Write a function called **get_gdp_health** which:\n",
        "\n",
        "1. sort the data by Economy (GDP per Capita) and Health (Life Expectancy) in ascending order \n",
        "2. display the first 5 rows of sorted data \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7XalX7OK0u-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed89052-e09e-4dbd-843d-da2e77e31033"
      },
      "source": [
        "def get_gdp_health(df):\n",
        "  # add code below to return a 5 row series which sorts rows by Economy and Health in ascending order \n",
        "  # print(df.head(10))\n",
        "  sorted_by_economy_health_df = df.sort_values(by = [\"Economy (GDP per Capita)\",\"Health (Life Expectancy)\"])\n",
        "  print(sorted_by_economy_health_df.head(5))\n",
        "\n",
        "\n",
        "  return sorted_by_economy_health_df\n",
        "\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the first row of your series has the correct happiness score \n",
        "# don't need to read df in again as should still have the excel contents contained in \"happiness\" df\n",
        "test = get_gdp_health(happiness)\n",
        "\n",
        "actual = test['Happiness Score'].iloc[0]\n",
        "expected = 4.517\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Well done, test passed\")\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Country              Region  ...  Generosity  Dystopia Residual\n",
            "119  Congo (Kinshasa)  Sub-Saharan Africa  ...     0.24834            2.86712\n",
            "156           Burundi  Sub-Saharan Africa  ...     0.19727            1.83302\n",
            "130            Malawi  Sub-Saharan Africa  ...     0.33128            2.80791\n",
            "143             Niger  Sub-Saharan Africa  ...     0.19387            1.87877\n",
            "115           Liberia  Sub-Saharan Africa  ...     0.24362            2.77729\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "Well done, test passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQ3cys4LHNc"
      },
      "source": [
        "### Exercise 3 - sorting in descending order \n",
        "---\n",
        "\n",
        "Write a function called **get_descending** which will: \n",
        "\n",
        "Sort the data by Freedom and Trust (Government Corruption) in descending order and show the Country and Region only for the last five rows\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3haPVvX7MCom",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6316ca4c-2fd8-4c30-8958-530a36ecaba2"
      },
      "source": [
        "def get_descending(df):\n",
        "  #add code below to return a series which contains the last 5 rows of Country and Region sorted by Freedom and Trust in descending order\n",
        "  sorted_by_freedom_df = df.sort_values(by = [\"Freedom\",\"Trust (Government Corruption)\"], ascending = False)\n",
        "  print(sorted_by_freedom_df.head(5))\n",
        "\n",
        "\n",
        "  return sorted_by_freedom_df.tail(5)\n",
        "\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the length and series are correct \n",
        "actual = get_descending(happiness).index[0]\n",
        "expected = 136\n",
        "\n",
        "if actual == expected and (len(get_descending(happiness)) == 5):\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 5 but was\", len(get_descending(happiness)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Country                      Region  ...  Generosity  Dystopia Residual\n",
            "3         Norway              Western Europe  ...     0.34699            2.46531\n",
            "0    Switzerland              Western Europe  ...     0.29678            2.51738\n",
            "144     Cambodia           Southeastern Asia  ...     0.40359            0.98195\n",
            "7         Sweden              Western Europe  ...     0.36262            2.37119\n",
            "43    Uzbekistan  Central and Eastern Europe  ...     0.22837            2.23741\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "         Country                      Region  ...  Generosity  Dystopia Residual\n",
            "3         Norway              Western Europe  ...     0.34699            2.46531\n",
            "0    Switzerland              Western Europe  ...     0.29678            2.51738\n",
            "144     Cambodia           Southeastern Asia  ...     0.40359            0.98195\n",
            "7         Sweden              Western Europe  ...     0.36262            2.37119\n",
            "43    Uzbekistan  Central and Eastern Europe  ...     0.22837            2.23741\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "Test passed 136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqnAoELjMDs7"
      },
      "source": [
        "# Cleaning the data\n",
        "\n",
        "Data comes from a range of sources:  forms, monitoring devices, etc.  There will often be missing values, duplicate records and values that are incorrectly formatted.  These can affect summary statistics and graphs plotted from the data.\n",
        "\n",
        "Techniques for data cleansing include:\n",
        "*  removing records with missing or null data (NaN, NA, \"\")\n",
        "*  removing duplicate rows (keeping just one, either the first or the last)\n",
        "\n",
        "Removal of rows according to criteria, or of columns are other ways that data might be cleaned up.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVqmfM5wk7NK"
      },
      "source": [
        "---\n",
        "\n",
        "## Removing NaN/Dropping NA values \n",
        "\n",
        "pandas have functions for checking a dataframe, or column, for null values, checking a column for missing values, and functions for dropping all rows that contain null values.\n",
        "\n",
        "* check for NA/NaN/missing values across dataframe (returns True if NA values exist)  \n",
        "  `df.isnull().values.any()`  \n",
        "\n",
        "* check for NA/NaN/missing values in specific column  \n",
        "  `df[\"column\"].isnull().values.any()`  \n",
        "\n",
        "* filter for non-null rows   \n",
        "  `df[~df[\"column\"].isnull()]`  \n",
        "  *hint: ~ means is not*\n",
        "\n",
        "* drop all rows that have NA/NaN values   \n",
        "  `df.dropna()`  \n",
        "\n",
        "* drop rows where NA/NaN values exist in specific columns  \n",
        "  `df.dropna(subset = [\"Make\", \"Model\"])`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC65hEZGOKNL"
      },
      "source": [
        "### Exercise 4 - check for null values \n",
        "---\n",
        "\n",
        "1. read data into a variable called **housing** from the file housing_in_london_yearly_variables.csv from this link: https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv \n",
        "\n",
        "Write a function called **check_null** which will:\n",
        "2. check if any NA values exist in the dataframe and print the result \n",
        "3. use df.info() to see which columns have null entries (*Hint: if the non-null count is less than total entries, column contains missing/NA entries*)  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7LYkXDNVVc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e612867-234f-4e66-917b-9c30faa7cd6e"
      },
      "source": [
        "def check_null(df):\n",
        "  # add code below to return a bool statement for whether or not there are null values \n",
        "  print(df.head(5))\n",
        "  # check if any NA values exist in the dataframe and print the result\n",
        "  check_null = df.isnull().values.any()\n",
        "  print(\"Nulls?: \",check_null)\n",
        "\n",
        "  return check_null\n",
        "\n",
        "# read data from url csv\n",
        "import pandas as pd\n",
        "url = \"https://raw.githubusercontent.com/futureCodersSE/working-with-data/main/Data%20sets/housing_in_london_yearly_variables.csv\"\n",
        "housing = pd.read_csv(url)\n",
        "\n",
        "# The code below will run and test your code to see if you are returning the correct answer\n",
        "actual = check_null(housing)\n",
        "expected = True\n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        code                  area  ... no_of_houses  borough_flag\n",
            "0  E09000001        city of london  ...          NaN             1\n",
            "1  E09000002  barking and dagenham  ...          NaN             1\n",
            "2  E09000003                barnet  ...          NaN             1\n",
            "3  E09000004                bexley  ...          NaN             1\n",
            "4  E09000005                 brent  ...          NaN             1\n",
            "\n",
            "[5 rows x 12 columns]\n",
            "Nulls?:  True\n",
            "Test passed True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTecutIXFJM"
      },
      "source": [
        "### Exercise 5 - filter for non-null rows\n",
        "---\n",
        "\n",
        "Create function called **filter_null()** which filters the non-null rows by the `number_of_jobs` column. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fWi0_MLXEzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29700aee-bcd2-482c-a82a-c39676ba08ff"
      },
      "source": [
        "def filter_null(df):\n",
        "  # add code below to filter out null values\n",
        "  \n",
        "  # filter for non-null rows\n",
        "  filtered_df = df[~df[\"number_of_jobs\"].isnull()] #need to assign a new df\n",
        "  print (filtered_df.head(15))\n",
        "  \n",
        "  return filtered_df\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if the length of your returned dataframe is correct\n",
        "\n",
        "actual = len(filter_null(housing))\n",
        "expected = 931 \n",
        "\n",
        "if actual == expected:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed expected\", expected, \"got\", actual)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         code                    area  ... no_of_houses  borough_flag\n",
            "51  E09000001          city of london  ...          NaN             1\n",
            "52  E09000002    barking and dagenham  ...          NaN             1\n",
            "53  E09000003                  barnet  ...          NaN             1\n",
            "54  E09000004                  bexley  ...          NaN             1\n",
            "55  E09000005                   brent  ...          NaN             1\n",
            "56  E09000006                 bromley  ...          NaN             1\n",
            "57  E09000007                  camden  ...          NaN             1\n",
            "58  E09000008                 croydon  ...          NaN             1\n",
            "59  E09000009                  ealing  ...          NaN             1\n",
            "60  E09000010                 enfield  ...          NaN             1\n",
            "61  E09000011               greenwich  ...          NaN             1\n",
            "62  E09000012                 hackney  ...          NaN             1\n",
            "63  E09000013  hammersmith and fulham  ...          NaN             1\n",
            "64  E09000014                haringey  ...          NaN             1\n",
            "65  E09000015                  harrow  ...          NaN             1\n",
            "\n",
            "[15 rows x 12 columns]\n",
            "Test passed 931\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRBLm_bJVItu"
      },
      "source": [
        "### Exercise 5 - remove null values \n",
        "---\n",
        "Write a function called **drop_null** which will:\n",
        "1. remove rows with NA values for `life_satisfaction` (use [ ] even if only one column in list)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjZJNIC3QObK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32816bb8-42b3-4311-e741-d9175f12ce6e"
      },
      "source": [
        "def drop_null(df):\n",
        "  # add code which returns a dataframe with rows that contain NA values in the life_satisfaction column removed\n",
        "  df_dropped_null = df.dropna(subset = [\"life_satisfaction\"])\n",
        "  print(df_dropped_null.head(4))\n",
        "  return  df_dropped_null\n",
        "\n",
        "\n",
        "# The code below will run and test your code to see if you have returned a series with the correct length and first row\n",
        "actual = drop_null(housing).index[0]\n",
        "expected = 613 \n",
        "\n",
        "if actual == expected and len(drop_null(housing)) == 352:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 352 but was\", len(drop_null(housing))) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          code                  area  ... no_of_houses  borough_flag\n",
            "613  E09000002  barking and dagenham  ...      71079.0             1\n",
            "614  E09000003                barnet  ...     139346.0             1\n",
            "615  E09000004                bexley  ...      95037.0             1\n",
            "616  E09000005                 brent  ...     112083.0             1\n",
            "\n",
            "[4 rows x 12 columns]\n",
            "          code                  area  ... no_of_houses  borough_flag\n",
            "613  E09000002  barking and dagenham  ...      71079.0             1\n",
            "614  E09000003                barnet  ...     139346.0             1\n",
            "615  E09000004                bexley  ...      95037.0             1\n",
            "616  E09000005                 brent  ...     112083.0             1\n",
            "\n",
            "[4 rows x 12 columns]\n",
            "Test passed 613\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ui8HF5z8SiK8"
      },
      "source": [
        "## Dropping duplicates\n",
        "---\n",
        "\n",
        "* To remove duplicate rows based on duplication of values in all columns  \n",
        "  `df.drop_duplicates()`  \n",
        "\n",
        "* To remove rows that have duplicate entries in a specified column  \n",
        "  `df.drop_duplicates(subset = ['Make'])`  \n",
        "\n",
        "* To remove rows that have duplicate entries in multiple columns  \n",
        "  `df.drop_duplicates(subset = ['Make', 'Model'])` \n",
        "\n",
        "* Remove duplicate rows keeping the last instance rather than the first (default):  \n",
        "  `df.drop_duplicates(keep='last')`  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2Qf6uMxSb5t"
      },
      "source": [
        "### Exercise 6 - Removing duplicate entries \n",
        "---\n",
        "Write a function called **drop_duplicates** which will: \n",
        "\n",
        "remove duplicate `area` entries keeping first instance  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ8T0tYVQj74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5861a859-4b31-4d3f-a360-500fd5ce7a87"
      },
      "source": [
        "def drop_duplicates(df):\n",
        "  # add code which returns a dataframe without duplicate area entries with first instance kept \n",
        "  df_no_duplicates = df.drop_duplicates(subset = ['area'],keep = 'first')\n",
        "  print(df_no_duplicates.tail(10))\n",
        "  return df_no_duplicates\n",
        "\n",
        "# The code below will run and test your code to see if you have returned a series with the correct length and first row\n",
        "actual = drop_duplicates(housing).index[0]\n",
        "expected = 0\n",
        "\n",
        "if actual == expected and len(drop_duplicates(housing)) == 51:\n",
        "  print(\"Test passed\", actual)\n",
        "else:\n",
        "  print(\"Test failed\",\"Should have got\", expected, \"got\", actual, \"and length of series should have been 51 but was\", len(drop_duplicates(housing))) "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         code               area  ... no_of_houses  borough_flag\n",
            "41  E12000009         south west  ...          NaN             0\n",
            "42  E13000001       inner london  ...          NaN             0\n",
            "43  E13000002       outer london  ...          NaN             0\n",
            "44  E92000001            england  ...          NaN             0\n",
            "45  K02000001     united kingdom  ...          NaN             0\n",
            "46  K03000001      great britain  ...          NaN             0\n",
            "47  K04000001  england and wales  ...          NaN             0\n",
            "48  N92000002   northern ireland  ...          NaN             0\n",
            "49  S92000003           scotland  ...          NaN             0\n",
            "50  W92000004              wales  ...          NaN             0\n",
            "\n",
            "[10 rows x 12 columns]\n",
            "         code               area  ... no_of_houses  borough_flag\n",
            "41  E12000009         south west  ...          NaN             0\n",
            "42  E13000001       inner london  ...          NaN             0\n",
            "43  E13000002       outer london  ...          NaN             0\n",
            "44  E92000001            england  ...          NaN             0\n",
            "45  K02000001     united kingdom  ...          NaN             0\n",
            "46  K03000001      great britain  ...          NaN             0\n",
            "47  K04000001  england and wales  ...          NaN             0\n",
            "48  N92000002   northern ireland  ...          NaN             0\n",
            "49  S92000003           scotland  ...          NaN             0\n",
            "50  W92000004              wales  ...          NaN             0\n",
            "\n",
            "[10 rows x 12 columns]\n",
            "Test passed 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQyytEbnZ1lw"
      },
      "source": [
        "# Reflection\n",
        "----\n",
        "\n",
        "## What skills have you demonstrated in completing this notebook?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM00hR5aZk1-"
      },
      "source": [
        "filtering out rows with nulls or duplicates "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zgexd27sZ1ly"
      },
      "source": [
        "## What caused you the most difficulty?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y_nrVBwaGXr"
      },
      "source": [
        "syntax especially of df[~df[\"number_of_jobs\"].isnull()] "
      ]
    }
  ]
}